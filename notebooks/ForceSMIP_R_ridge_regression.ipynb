{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a06a33-4d6c-4a25-ba6b-6241d3186171",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ForceSMIP Minimal Example: Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29a1cc-c32b-401f-a0b7-a86415c97cda",
   "metadata": {},
   "source": [
    "The goal of this notebook is to demonstrate the use of ridge regression to estimate the forced and unforced components of global mean surface temperature variability and change. This is the place where you introductory information about your project, and also the place to work on your group project. \n",
    "\n",
    "Outline:\n",
    "\n",
    "* Notes on setup with conda\n",
    "* Import of key packages\n",
    "* Surveying the ForceSMIP provided data\n",
    "* Looping over each available climate model to:\n",
    "* Finding and looping over all available ensemble members\n",
    "* Loading data for each member\n",
    "* Calculating the annual average departure (from 1900 - 1949)\n",
    "* Storing full fields for a subset of the ensemble (to be used for our training/prediction)\n",
    "* Calculating and storing the global mean time series for all members\n",
    "* Calculate the forced response for each model by taking the ensemble mean of all global mean time series\n",
    "\n",
    "* Train a regression model based on a random grid cell for reference and comparison\n",
    "* Create predictor and predictand matrices\n",
    "* Train Ridge Regression Model\n",
    "* See how well model works on ensemble members not used in training dataset\n",
    "\n",
    "* Run prediction with ridge regression for the Tier 1 test dataset\n",
    "\n",
    "Reference: The notebook implements the main method from this paper, which was presented in the lecture: Sippel et al., (2020), *Nature Climate Change*, Climate change now detectable from any single day of weather at global scale https://www.nature.com/articles/s41558-019-0666-7. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b71db66-ecf4-40b6-bdd3-786d7e739457",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Recommended: Choose your (existing) kernel\n",
    "\n",
    "Before you can start, navigate to Kernel-> Change Kernel, and choose the Kernel \"Teaching - R_ForceSMIP3\". Alternatively, you can create your own conda environement (follow instructions below), but this is not necessary.\n",
    "\n",
    "#### Alternative: Create your own conda environment for your project\n",
    "\n",
    "Before you can start, we need to create an environment, which runs your R version and all packages you need. To create the conda environment, please follow the following commands:\n",
    "\n",
    "1. Move to File -> Launcher, and open a Terminal.\n",
    "\n",
    "2. Load the conda environment manager, by typing: `module load conda`\n",
    "\n",
    "3. Create a new environment with a name (e.g., 'R_ForceSMIP') with the respective dependencies installed: \n",
    "`conda create --name R_ForceSMIP3 r r-base=4.2.3 r-essentials r-ncdf4 r-ncdf4.helpers r-raster r-irkernel r-matrixStats r-rnaturalearth r-rnaturalearthdata r-doParallel r-foreach --y` (this will run a couple of minutes)\n",
    "\n",
    "4. When the command has run, restart you Jupyter Lab Session, and select Kernel->Change Kernel, and choose your new Kernel `R [conda env:.conda-R_ForceSMIP]`\n",
    "\n",
    "Now, you're ready to go!\n",
    "\n",
    "If you need to install further packages later, you can easily do so in the Terminal session, e.g.: \n",
    "`source activate R_ForceSMIP`, followed by, for example: `conda install r-ncdf4` (which would install the ncdf4 R package)\n",
    "To learn more about conda, you can use the Cheatsheeet here: https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7925fa5f-1e91-4f2c-8161-4e3347faffde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for internal use:\n",
    "# cp /home/sippels/IAC_lectures/2023_ForceSMIP/Ridge_Regression/ridge_regression.ipynb /net/iacftp/ftp/pub_read/sippels/ForceSMIP/notebook_RR/ridge_regression.ipynb\n",
    "# Path to publicly readable FRP directory: ftp://iacftp.ethz.ch/pub_read/sippels/ForceSMIP/notebook_RR/ridge_regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "834655eb-9b55-4f12-8730-a84e2e58fc65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: sp\n",
      "\n",
      "The legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\n",
      "which was just loaded, will retire in October 2023.\n",
      "Please refer to R-spatial evolution reports for details, especially\n",
      "https://r-spatial.org/r/2023/05/15/evolution4.html.\n",
      "It may be desirable to make the sf package available;\n",
      "package maintainers should consider adding sf to Suggests:.\n",
      "The sp package is now running under evolution status 2\n",
      "     (status 2 uses the sf package in place of rgdal)\n",
      "\n",
      "Support for Spatial objects (`sp`) will be deprecated in {rnaturalearth} and will be removed in a future release of the package. Please use `sf` objects with {rnaturalearth}. For example: `ne_download(returnclass = 'sf')`\n",
      "\n",
      "\n",
      "Attaching package: ‘rnaturalearthdata’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:rnaturalearth’:\n",
      "\n",
      "    countries110\n",
      "\n",
      "\n",
      "Loading required package: Matrix\n",
      "\n",
      "Loaded glmnet 4.1-8\n",
      "\n",
      "\n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:raster’:\n",
      "\n",
      "    extract\n",
      "\n",
      "\n",
      "Loading required package: foreach\n",
      "\n",
      "Loading required package: iterators\n",
      "\n",
      "Loading required package: parallel\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               _                           \n",
       "platform       x86_64-conda-linux-gnu      \n",
       "arch           x86_64                      \n",
       "os             linux-gnu                   \n",
       "system         x86_64, linux-gnu           \n",
       "status                                     \n",
       "major          4                           \n",
       "minor          2.3                         \n",
       "year           2023                        \n",
       "month          03                          \n",
       "day            15                          \n",
       "svn rev        83980                       \n",
       "language       R                           \n",
       "version.string R version 4.2.3 (2023-03-15)\n",
       "nickname       Shortstop Beagle            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################################################\n",
    "## 0.a. required packages\n",
    "########################################################################\n",
    "\n",
    "library(ncdf4)\n",
    "library(ncdf4.helpers)\n",
    "library(data.table)\n",
    "library(raster)\n",
    "library(rnaturalearth)\n",
    "library(rnaturalearthdata)\n",
    "library(matrixStats)\n",
    "library(ggplot2)\n",
    "library(glmnet)\n",
    "library(magrittr)\n",
    "\n",
    "library(doParallel)\n",
    "library(foreach)\n",
    "\n",
    "R.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c92c9f-ed53-45c5-b05b-62fbec69f83d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "## 0.b. required functions\n",
    "########################################################################\n",
    "\n",
    "# Gets the raw data of specified variable out of the netcdf file\n",
    "extract_data <- function(in_file, var = NULL){\n",
    "  ncfile <- nc_open(in_file)\n",
    "  ncdata <- ncvar_get(nc = ncfile, varid = var)\n",
    "  nc_close(ncfile)\n",
    "  return(ncdata)\n",
    "}\n",
    "\n",
    "# Extracts annual data from the monthly netCDF files \n",
    "# (monthly resolution not needed for the ridge forced resp. estimate)\n",
    "extract_data_annual <- function(in_file, temp.file = c(\"/home/sippels/test.nc\"), var = NULL){\n",
    "  print(paste(\"processed: \", in_file))\n",
    "  system(paste(\"cdo -O -yearmean \", in_file,\" \", temp.file, sep=\"\"))\n",
    "  ncfile <- nc_open(temp.file)\n",
    "  ncdata <- ncvar_get(nc = ncfile, varid = var)\n",
    "  nc_close(ncfile)\n",
    "  file.remove(temp.file)\n",
    "  return(ncdata)\n",
    "  #system(paste(\"rm \", temp.file, sep=\"\"))\n",
    "}\n",
    "\n",
    "\n",
    "# Helper function for the areaw_avg function, produces weights for every grid cell\n",
    "get_area_weights <- function(res = 2.5){\n",
    "  raster.template = raster(res = res, xmn = 0, xmx=360, ymn = -90, ymx=90)\n",
    "  y <- dim(raster.template)[1]\n",
    "  x <- dim(raster.template)[2]\n",
    "  areaw=c(matrix(values(raster::area(raster.template)), x,y)[,y:1]) / sum(c(matrix(values(raster::area(raster.template)), x,y)[,y:1]))\n",
    "  return(areaw)\n",
    "}\n",
    "\n",
    "# Calculates an area weighted average based on a specific mask. \n",
    "# usage here is not going to require masking (i think) so the mask will usually be the entire globe\n",
    "areaw_avg <- function(X, mask, apply_mask = T){\n",
    "  area_weghts <- get_area_weights()\n",
    "  area_weghts_masked <- area_weghts[mask] * 10368/length(mask)\n",
    "  if(apply_mask){\n",
    "    avg <-  c(X[,mask] %*% area_weghts_masked)\n",
    "  }else{\n",
    "    avg <-  c(X %*% area_weghts_masked)\n",
    "  }\n",
    "  return(avg)\n",
    "}\n",
    "\n",
    "# Helper function to get lat and lon as coordinates of each grid cell's center (requires next function convert.to.Pacific)\n",
    "get_lonlatDT <- function(res = 2.5, SREX = F){\n",
    "  require(raster)\n",
    "  r_template = raster(res = res, xmn = -180, xmx=180, ymn = -90, ymx=90)\n",
    "  r_template <- convert.to.pacific(r_template)\n",
    "  lonlatDT <- data.table(\n",
    "    lat = c(matrix(coordinates(r_template)[,2],144, 72)[,72:1]),\n",
    "    lon = coordinates(r_template)[,1])\n",
    "  lonlatDT[lon > 180, lon := lon -360]\n",
    "  lonlatDT[, lonlat := paste(lon,lat)]\n",
    "  \n",
    "  if(SREX == T){\n",
    "    load(\"/net/xenon/climphys_backedup/maegli/Misc/SREX/IPCC-WGI-reference-regions-v4_R.rda\")\n",
    "    \n",
    "    for(i in 1:length( names(IPCC_WGI_reference_regions_v4@polygons))){\n",
    "      region <- names(IPCC_WGI_reference_regions_v4@polygons)[i]\n",
    "      region_ix <- which(names(IPCC_WGI_reference_regions_v4@polygons) == region)\n",
    "      \n",
    "      x <- IPCC_WGI_reference_regions_v4@polygons[[region_ix]]@Polygons[[1]]@coords[,1]\n",
    "      y <- IPCC_WGI_reference_regions_v4@polygons[[region_ix]]@Polygons[[1]]@coords[,2]\n",
    "      \n",
    "      SREX_mask <- which(point.in.polygon(lonlatDT$lon, lonlatDT$lat, x, y) == 1)\n",
    "      \n",
    "      lonlatDT[SREX_mask, SREX := region]\n",
    "    } \n",
    "  }\n",
    "  \n",
    "  \n",
    "  return(lonlatDT)\n",
    "}\n",
    "\n",
    "\n",
    "# Helper function to make everything Pacific-centered (raster package left bound is at 0 Meridian..)\n",
    "convert.to.pacific <- function(raster.in) {\n",
    "  rl <- crop(raster.in, extent(c(xmin(raster.in)+180,xmax(raster.in),ymin(raster.in), ymax(raster.in))))\n",
    "  \n",
    "  # set extent from rr to rleft:\n",
    "  rr <- (crop(raster.in, extent(c(xmin(raster.in),xmax(raster.in)-180,ymin(raster.in), ymax(raster.in)))))\n",
    "  extent(rr) <- extent(c(xmin(rr)+360,xmax(rr)+360,ymin(raster.in), ymax(raster.in)))\n",
    "  \n",
    "  r.out = merge(rr,rl)\n",
    "  names(r.out) = names(raster.in)\n",
    "  \n",
    "  return(r.out)\n",
    "}\n",
    "\n",
    "\n",
    "# subtract reference period based on monthly data frame:\n",
    "center.XAX_mon <- function(XAX, ref.period.years = 1950:2000) {\n",
    "  \n",
    "  XAX_norm = XAX\n",
    "  XAX_norm$X[,] = NA\n",
    "  \n",
    "  mod.un = unique(as.character(XAX$M$mod))\n",
    "  \n",
    "  for (mon in 1:12) {\n",
    "    for (m in 1:length(mod.un)) {\n",
    "      print(paste(mod.un[m], \"- Month:\", mon))\n",
    "      mod.ix = which(XAX$M$mod == mod.un[m] & XAX$M$mon == mon)\n",
    "      ref.mod.ix = which(XAX$M$mod == mod.un[m] & XAX$M$year %in% ref.period.years & XAX$M$mon == mon)\n",
    "      \n",
    "      clim_mean = apply(X = XAX$X[ref.mod.ix,], MARGIN = 2, FUN = mean)\n",
    "      XAX_norm$X[mod.ix,] = t(t(XAX$X[mod.ix,]) - clim_mean)\n",
    "    }\n",
    "  }\n",
    "  return(XAX_norm)\n",
    "}\n",
    "\n",
    "# subtract reference period based on annual data:\n",
    "center.XAX_ann <- function(XAX, ref.period.years = 1950:2000) {\n",
    "  \n",
    "  XAX_norm = XAX\n",
    "  XAX_norm$X[,] = NA\n",
    "  \n",
    "  mod.un = unique(as.character(XAX$M$mod))\n",
    "  \n",
    "  for (m in 1:length(mod.un)) {\n",
    "    #print(paste(mod.un[m], \"- Month:\", mon))\n",
    "    mod.ix = which(XAX$M$mod == mod.un[m])\n",
    "    ref.mod.ix = which(XAX$M$mod == mod.un[m] & XAX$M$year %in% ref.period.years)\n",
    "    \n",
    "    clim_mean = apply(X = XAX$X[ref.mod.ix,], MARGIN = 2, FUN = mean)\n",
    "    XAX_norm$X[mod.ix,] = t(t(XAX$X[mod.ix,]) - clim_mean)\n",
    "  }\n",
    "  return(XAX_norm)\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef8018-6221-4371-8958-2993db6dc5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "## 01. Training Data Read-In  \n",
    "########################################################################\n",
    "\n",
    "input_dir <- \"/net/krypton/climdyn_nobackup/FTP/ForceSMIP/Training/Amon/tas/\"\n",
    "#read files stored in input directory\n",
    "input_files <- list.files(input_dir, recursive = T)\n",
    "\n",
    "# !!!IMPORTANT!!! Define the temporary file in a directory where you have writing permissions. \n",
    "# I.e., replace 'sippels' with *your* User name: \n",
    "temp.file = \"/home/sippels/temp.nc\"  \n",
    "\n",
    "#creating a data frame containg the meta data stored in the file strings \n",
    "# Later we add also the timestamps of the netcdf files in input_files\n",
    "split_strings <- strsplit(input_files, \"_\")\n",
    "meta_data <- data.frame(matrix(unlist(split_strings), ncol = max(lengths(split_strings)), byrow = TRUE))\n",
    "colnames(meta_data) <-  c(\"var\", \"res\", \"mod\", \"scen1\", \"scen2\", \"rest\")\n",
    "\n",
    "# Get full directory name to all input files\n",
    "full_input_files <- sapply(input_files, function(x) paste0(input_dir, x))\n",
    "\n",
    "# Create a list ForceSMIP_train, which will contain the training data X, the metadata M, and the corresponding response Y. \n",
    "# Each one of X, M and Y will correspond to one list entry. ForceSMIP thus is a list with three entries, X, M and Y.  \n",
    "ForceSMIP_train <- list()\n",
    "\n",
    "# Creating M.. \n",
    "meta_list <- list()\n",
    "for(i in 1:nrow(meta_data)){\n",
    "  #print(i)\n",
    "  timestamps <- substr(nc.get.time.series(nc_open(full_input_files[i])),1, 10)\n",
    "  meta_list[[i]] <- data.frame(matrix(rep(as.character(meta_data[i,]), length(timestamps)), ncol = ncol(meta_data), byrow = TRUE))\n",
    "  colnames(meta_list[[i]]) <- c(\"var\", \"res\", \"mod\", \"scen1\", \"scen2\", \"rest\")\n",
    "  #meta_list[[i]][, rest := unlist(rest)]\n",
    "  meta_list[[i]]$ens.mem = substr(meta_list[[i]]$rest, 1, 15)\n",
    "  meta_list[[i]]$time = timestamps\n",
    "  meta_list[[i]]$year = as.integer(substr(meta_list[[i]]$time, 1,4))\n",
    "  #meta_list[[i]]$mon =  as.integer(substr(meta_list[[i]]$time, 6,7))\n",
    "  #meta_list[[i]]$day =  as.integer(substr(meta_list[[i]]$time, 9,10))\n",
    "  # for annual data:\n",
    "  meta_list[[i]] = meta_list[[i]][seq(6, 1716, 12),]\n",
    "  meta_list[[i]]$res = \"ann\"\n",
    "}\n",
    "\n",
    "ForceSMIP_train$M<- data.frame(do.call(\"rbind\", meta_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e8b2e-351a-4f6f-a36d-c543f69bebe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explore the meta data:\n",
    "str(ForceSMIP_train$M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760c3fa-3b9a-42ff-b146-3fbb8849870b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating X, meaning processing+reading the actual *annual* data:\n",
    "# Be PATIENT, this step may take up to 5 minutes!!\n",
    "\n",
    "raw_data <- list()\n",
    "for (i in 1:length(full_input_files)) {\n",
    "  print(i)\n",
    "  raw_data[[i]] = extract_data_annual(in_file = full_input_files[i], temp.file = temp.file, var = \"tas\")\n",
    "}\n",
    "\n",
    "ForceSMIP_train$X <- do.call(\"rbind\", lapply(raw_data, function(x) t(apply(x,3,as.vector))))\n",
    "\n",
    "# Subtract reference period, so that each grid cell is centered around its own 1950-2000 mean:\n",
    "# (This is necessary to ensure the there are no model-specific mean-state biases in the training data, \n",
    "# i.e., a region that is typically too warm or too cold)\n",
    "ForceSMIP_train <- center.XAX_ann(XAX = ForceSMIP_train, ref.period.years = 1950:2000)\n",
    "\n",
    "# Now add also the response Y to the list ForceSMIP_train\n",
    "ForceSMIP_train$Y <- list()\n",
    "\n",
    "#caclucalte forced response (ensemble mean global mean surface temperature)\n",
    "ForceSMIP_train$Y$GMST <- areaw_avg(ForceSMIP_train$X, 1:dim(ForceSMIP_train$X)[2])\n",
    "ForceSMIP_train$Y$FR <- data.table(GMST = ForceSMIP_train$Y$GMST,\n",
    "                                   year = ForceSMIP_train$M$year,\n",
    "                                   mod = ForceSMIP_train$M$mod)[\n",
    "                                     , FR := mean(GMST), by = list(mod, year)][,FR]\n",
    "#clean up\n",
    "rm(raw_data)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355a76c-ff00-4cae-923e-ae2c32768453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "########################################################################\n",
    "## 01. Predicting the FR by regressing a random grid cell onto the FR\n",
    "########################################################################\n",
    "\n",
    "# Split the data into a training and a testing data set. We use one random ensemble member for testing, \n",
    "# and all remaining ens. members for training. We train on all models simulatenously \n",
    "train_ix <- which(ForceSMIP_train$M$ens.mem != \"r1011.001i1p1f1\")\n",
    "test_ix <- which(ForceSMIP_train$M$ens.mem == \"r1011.001i1p1f1\")\n",
    "\n",
    "#randomaly selects a grid cell from which to predict the forced response\n",
    "set.seed(1234)\n",
    "loc <- sample(1:dim(ForceSMIP_train$X)[2], 1)\n",
    "\n",
    "y <- ForceSMIP_train$Y$FR[train_ix]\n",
    "x <- ForceSMIP_train$X[train_ix,loc]\n",
    "\n",
    "fit <- lm(y~ x)\n",
    "\n",
    "#test the model with the left out ensemble meber and generate scatterplot\n",
    "test_data <- data.frame(x = ForceSMIP_train$X[test_ix,loc])\n",
    "y_pred <- predict(fit, test_data)\n",
    "\n",
    "data.table(pred = y_pred,\n",
    "           true = ForceSMIP_train$Y$FR[test_ix],\n",
    "           year = ForceSMIP_train$M$year[test_ix]) %>% \n",
    "  ggplot()+\n",
    "  geom_point(aes(pred, true, color = year))+\n",
    "  scale_color_viridis_c()\n",
    "\n",
    "\n",
    "# very poor performance...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568d1f8-01f2-4b4e-9228-e4ea8ac4be0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "## 02a. Ridge regression (takes some time to run)\n",
    "########################################################################\n",
    "\n",
    "registerDoParallel(cores=5)\n",
    "\n",
    "# define 20 members per model for training:\n",
    "mod.un = unique(ForceSMIP_train$M$mod)\n",
    "\n",
    "train.ens.mem = c(sapply(X = mod.un, FUN = function(mod) { unique(ForceSMIP_train$M$ens.mem[which(ForceSMIP_train$M$mod == mod)])[1:20] }))\n",
    "train.mod = c(rep(\"CanESM5\", 20), rep(\"CESM2\", 20), rep(\"MIROC-ES2L\", 20), rep(\"MIROC6\", 20), rep(\"MPI-ESM1-2-LR\", 20))\n",
    "train_ix <- which(ForceSMIP_train$M$ens.mem %in% train.ens.mem & ForceSMIP_train$M$mod %in% train.mod)\n",
    "\n",
    "\n",
    "test.ens.mem = c(sapply(X = mod.un, FUN = function(mod) { unique(ForceSMIP_train$M$ens.mem[which(ForceSMIP_train$M$mod == mod)])[21:25] }))\n",
    "test.mod = c(rep(\"CanESM5\", 5), rep(\"CESM2\", 5), rep(\"MIROC-ES2L\", 5), rep(\"MIROC6\", 5), rep(\"MPI-ESM1-2-LR\", 5))\n",
    "test_ix <- which(ForceSMIP_train$M$ens.mem %in% test.ens.mem & ForceSMIP_train$M$mod %in% test.mod)\n",
    "\n",
    "# We now defines the cross validation folds, used for the lambda estimation\n",
    "# Each member is it's own cross validation fold, leading to a high number of folds\n",
    "# This makes the fitting procedure a bit slow \n",
    "crossclass <- as.numeric(as.factor(ForceSMIP_train$M$mod[train_ix]))\n",
    "\n",
    "#fit the ridge model\n",
    "ridge_fit <- cv.glmnet(x = ForceSMIP_train$X[train_ix, ],\n",
    "                       y = ForceSMIP_train$Y$FR[train_ix],\n",
    "                       foldid = crossclass,\n",
    "                       alpha = 0, parallel = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab2c58c-70de-411d-9813-6d04173d2691",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot the ridge regression predictions against underlying data\n",
    "\n",
    "Explore the data and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19774ed-7642-4a3b-9da7-eaedc05e7c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "## 02b. Explore the results of the ridge regression fit\n",
    "########################################################################\n",
    "\n",
    "\n",
    "#generate scatter plot of predicted vs target\n",
    "pred_table <- data.table(pred = c(predict(ridge_fit, ForceSMIP_train$X[test_ix, ], s = \"lambda.1se\")),\n",
    "                         true = ForceSMIP_train$Y$FR[test_ix],\n",
    "                         year = ForceSMIP_train$M$year[test_ix])\n",
    "\n",
    "#scatter plot\n",
    "ggplot(pred_table)+\n",
    "  geom_point(aes(pred, true))\n",
    "\n",
    "#time series\n",
    "pred_table %>% melt(id.vars = \"year\") %>% \n",
    "  ggplot()+\n",
    "  geom_line(aes(year, value, color = variable))\n",
    "\n",
    "plot(pred_table$year, pred_table$true, col = \"black\")\n",
    "points(pred_table$year, pred_table$pred, col = \"red\")\n",
    "\n",
    "\n",
    "#borders for map plot\n",
    "world <- rnaturalearth::ne_countries(scale = \"medium\", returnclass = \"sf\")\n",
    "\n",
    "sds_tas <- c(matrixStats::colSds(ForceSMIP_train$X))\n",
    "\n",
    "world <- rnaturalearth::ne_countries(scale = \"medium\", returnclass = \"sf\")\n",
    "\n",
    "lonlatDT <- get_lonlatDT(res = 2.5, SREX = F)\n",
    "lonlatDT[, betas := ridge_fit$glmnet.fit$beta[,ridge_fit$index[2]]]\n",
    "lonlatDT[, sds := sds_tas]\n",
    "lonlatDT[, scaled_betas := betas*sds_tas]\n",
    "\n",
    "#map plot\n",
    "ggplot(lonlatDT) +\n",
    "  geom_tile(aes(lon, lat, fill = scaled_betas))+\n",
    "  geom_sf(data = world, fill=alpha(\"lightgrey\", 0), color=\"grey50\") +\n",
    "  ylab(\"\") + xlab(\"\") +\n",
    "  scale_fill_gradient2(high = \"#c90202\", mid = \"white\", low =\"#0237c9\", name= \"Scaled Coefficients\") +\n",
    "  theme(panel.grid.major = element_blank()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a75d90-ae90-466a-b98f-14600c0e7adb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example application of trained ridge regression model onto Tier 1 Evaluation to estimate forced response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e27106-6bf7-477a-a1c6-6ff19a2830aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "## 05a. Read-In of Out-of-sample(!!) Tier1 testing data\n",
    "########################################################################\n",
    "\n",
    "input_dir <- \"/net/krypton/climdyn_nobackup/FTP/ForceSMIP/Evaluation-Tier1/Amon/tas/\"\n",
    "#read files stored in input directory\n",
    "input_files <- list.files(input_dir, recursive = T)\n",
    "\n",
    "# !!!IMPORTANT!!! Define the temporary file in a directory where you have writing permissions. \n",
    "# I.e., replace 'sippels' with *your* User name: \n",
    "temp.file = \"/home/sippels/temp.nc\"\n",
    "\n",
    "#creating a data frame containg the meta data stored in the file strings as well as the timestamps of the netcdf files in input_files\n",
    "split_strings <- strsplit(input_files, \"_\")\n",
    "meta_data <- data.frame(matrix(unlist(split_strings), ncol = max(lengths(split_strings)), byrow = TRUE))\n",
    "colnames(meta_data) <-  c(\"var\", \"res\", \"mod\")\n",
    "\n",
    "full_input_files <- sapply(input_files, function(x) paste0(input_dir, x))\n",
    "ForceSMIP_test <- list()\n",
    "meta_list <- list()\n",
    "for(i in 1:nrow(meta_data)){\n",
    "  print(i)\n",
    "  timestamps <- substr(nc.get.time.series(nc_open(full_input_files[i])),1, 10)\n",
    "  meta_list[[i]] <- data.frame(matrix(rep(as.character(meta_data[i,]), length(timestamps)), ncol = ncol(meta_data), byrow = TRUE))\n",
    "  colnames(meta_list[[i]]) <- c(\"var\", \"res\", \"mod\")\n",
    "  #meta_list[[i]][, rest := unlist(rest)]\n",
    "  meta_list[[i]]$time = timestamps\n",
    "  meta_list[[i]]$year = as.integer(substr(meta_list[[i]]$time, 1,4))\n",
    "  #meta_list[[i]]$mon =  as.integer(substr(meta_list[[i]]$time, 6,7))\n",
    "  #meta_list[[i]]$day =  as.integer(substr(meta_list[[i]]$time, 9,10))\n",
    "  # for annual data:\n",
    "  meta_list[[i]] = meta_list[[i]][seq(6, 73*12, 12),]\n",
    "  meta_list[[i]]$res = \"ann\"\n",
    "}\n",
    "\n",
    "ForceSMIP_test$M<- data.frame(do.call(\"rbind\", meta_list))\n",
    "\n",
    "# ForceSMIP_train$X[1,] == ForceSMIP_train$X[144,]\n",
    "# ForceSMIP_train$M[1,] ; ForceSMIP_train$M[144,]\n",
    "# raw_data[[1]] == raw_data[[2]]\n",
    "\n",
    "#reading the actual data:\n",
    "raw_data <- list()\n",
    "for (i in 1:length(full_input_files)) {\n",
    "  print(i)\n",
    "  raw_data[[i]] = extract_data_annual(in_file = full_input_files[i], temp.file = temp.file, var = \"tas\")\n",
    "}\n",
    "\n",
    "ForceSMIP_test$X <- do.call(\"rbind\", lapply(raw_data, function(x) t(apply(x,3,as.vector))))\n",
    "#subtract reference period:\n",
    "ForceSMIP_test <- center.XAX_ann(XAX = ForceSMIP_test, ref.period.years = 1950:2000)\n",
    "\n",
    "ForceSMIP_test$Y <- list()\n",
    "#caclucalte forced response (ensemble mean global mean surface temperature)\n",
    "ForceSMIP_test$Y$GMST <- areaw_avg(ForceSMIP_test$X, 1:dim(ForceSMIP_test$X)[2])\n",
    "\n",
    "#clean up\n",
    "rm(raw_data)\n",
    "gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62077c8f-6c7c-4f4a-8d64-9fbb0ae6927d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "########################################################################\n",
    "## 05b. Get prediction for out-of-sample testing data:\n",
    "########################################################################\n",
    "\n",
    "pred_table <- data.table(pred = c(predict(ridge_fit, ForceSMIP_test$X, s = \"lambda.1se\")),\n",
    "                         var = ForceSMIP_test$M$var,\n",
    "                         res = ForceSMIP_test$M$res,\n",
    "                         mod = ForceSMIP_test$M$mod,\n",
    "                         year = ForceSMIP_test$M$year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132fd3a-12a9-4561-b83c-915e533551f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Some Discussion Questions (from Steven Po-Chedley's PLS notebook):\n",
    "\n",
    "* Why do you think the coefficient maps look the way they do?\n",
    "* Note that we trained and validated on the same five global climate models. How well do you think this would this work on out-of-sample models? On observations?\n",
    "* Observations have missing data. How would we apply this model-trained Ridge Regression model on observations?\n",
    "* The hyperparameter is chosen by cross-validation. What would happen if we chose a smaller or larger value of the hyperparameter $\\lambda$?\n",
    "* The ForceSMIP protocol asks for spatially resolved predictions of the forced response (e.g., [time, lat, lon]). How could you extend this notebook to go from global mean predictions to spatially resolved predictions?\n",
    "Do you think this approach would work well for other variables of interest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c0073d-79b1-45fc-a433-30e3717f7392",
   "metadata": {},
   "source": [
    "## Now it's your turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a7a60-9704-4f27-b4e6-b446c07c34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start coding here ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Teaching - R_ForceSMIP3",
   "language": "R",
   "name": "r_forcesmip3"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
